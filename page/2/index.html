<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <meta name="description" content="本人目前从事机器学习相关研究和工作，对机器学习和深度学习仍在入门阶段。开此博客，希望记录学习路上的一些体会，还有对生活的一些思考。" />
  

  
  <meta name="keywords" content="AI ML DL life" />
  
  
  
  
  
  
  <title>山风之行</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="本人目前从事机器学习相关研究和工作，对机器学习和深度学习仍在入门阶段。开此博客，希望记录学习路上的一些体会，还有对生活的一些思考。">
<meta name="keywords" content="AI ML DL life">
<meta property="og:type" content="website">
<meta property="og:title" content="山风之行">
<meta property="og:url" content="http://xurui.club/page/2/index.html">
<meta property="og:site_name" content="山风之行">
<meta property="og:description" content="本人目前从事机器学习相关研究和工作，对机器学习和深度学习仍在入门阶段。开此博客，希望记录学习路上的一些体会，还有对生活的一些思考。">
<meta property="og:locale" content="zh-Ch">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="山风之行">
<meta name="twitter:description" content="本人目前从事机器学习相关研究和工作，对机器学习和深度学习仍在入门阶段。开此博客，希望记录学习路上的一些体会，还有对生活的一些思考。">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  

  
  <!-- baidu webmaster push -->
  <script src='//push.zhanzhang.baidu.com/push.js'></script>
</head>
<body class="home blog custom-background custom-font-enabled single-author">
  <div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="山风之行" rel="home">山风之行</a>
      </h1>
      
        <h2 class="site-description">
          <a href="/" id="subtitle">—— 修养 风范 血性 胆识</a>
        </h2>
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">菜单</button>
            <a class="assistive-text" href="/#content" title="跳至内容">跳至内容</a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">主页</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives">文章</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/about">关于</a></li>
                
                </ul>
            </div>
    </nav>
</header>
      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main">
  
    <article id="post-keras-mask" class="post-keras-mask post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2018/05/12/keras-mask/">Keras 笔记之Mask层</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://xurui.club/2018/05/12/keras-mask/" data-id="cjisx1u6b0003owda82p1a9vb" class="leave-reply bdsharebuttonbox" data-cmd="more">分享</a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>keras 的Mask层<br>先看下官方文档的解释</p>
<hr>
<p>Masking层<br>keras.layers.core.Masking(mask_value=0.0)<br>使用给定的值对输入的序列信号进行“屏蔽”，用以定位需要跳过的时间步</p>
<p>对于输入张量的时间步，即输入张量的第1维度（维度从0开始算，见例子），如果输入张量在该时间步上都等于mask_value，则该时间步将在模型接下来的所有层（只要支持masking）被跳过（屏蔽）。</p>
<p>如果模型接下来的一些层不支持masking，却接受到masking过的数据，则抛出异常。</p>
<p>例子<br>考虑输入数据x是一个形如(samples,timesteps,features)的张量，现将其送入LSTM层。因为你缺少时间步为3和5的信号，所以你希望将其掩盖。这时候应该：</p>
<p>赋值x[:,3,:] = 0.，x[:,5,:] = 0.</p>
<p>在LSTM层之前插入mask_value=0.的Masking层</p>
<p>model = Sequential()<br>model.add(Masking(mask_value=0., input_shape=(timesteps, features)))<br>model.add(LSTM(32))</p>
<hr>
<p>在用LSTM等模型处理文本数据时，因为文本是变长的，所以在处理的过程中，要先进行长度的统一。常用的方法为<br><code>X_data = sequence.pad_sequence</code>(maxlen=10,value=0,padding=’post’)<br>此步骤将X_data统一长度为10.<br>如[1,2,3,4,5]–&gt;变为[1,2,3,4,5,0,0,0,0,0]<br>这样就可以把X_data 输入到model的Embedding等层。<br>然而，交给LSTM处理时，还有对数据进行反padding.也就是把后面的0去掉。<br>这个时候就是Mask层派上用场的时候了。Mask(0)经过Mask后，可以忽略X_data中所有的0，当然，把后面补的0去掉是可以理解的。那如果句中有0呢？一般情况下，如文本处理，会把文本映射成index，这样最大的好处就是节约空间。有些大文本数据，几百个G，经过了index映射，也就还剩几个G。这是题外话了，我们在keras的Embedding层会讲的。而这个时候index中的0,往往是一些无法转成词向量的低频词，这些词没有词向量，去掉对整个文本的处理也没有影响，所以在Mask中和补上的0一起忽略就好啦。<br>这里的忽略是什么意思呢？也就是不处理。<br>很多朋友以为Mask后会直接把0去掉。其实不是的。<br>可以做一些实验，如model的Mask后接个LSTM层，对LSTM输出每个时间步的值，发现，如果设置了Mask层，则上面[1,2,3,4,5,00000]的数据处理结果，前5位是经过了计算，补0的对应的位置的值，和第5位的值相同，也就是说LSTM对后面补0的位置并没有计算。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2018/05/12/keras-mask/">
    <time datetime="2018-05-12T11:36:39.000Z" class="entry-date">
        2018-05-12
    </time>
</a>
    
    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Keras/">Keras</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/技术/">技术</a></li></ul>

    </footer>
</article>






  
    <article id="post-tensorflow学习笔记3" class="post-tensorflow学习笔记3 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2018/04/27/tensorflow学习笔记3/">tensorflow学习笔记3</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://xurui.club/2018/04/27/tensorflow学习笔记3/" data-id="cjisx1u71000mowdah5kll6vt" class="leave-reply bdsharebuttonbox" data-cmd="more">分享</a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>实战,今天给大家举个回归例子，来说明下tensorflow的训练过程。</p>
<p>先贴上代码和注释。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引入包</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备好数据，x为生成-1到1之间的100个数，y为2*x+1+噪声</span></span><br><span class="line">data_x = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">data_y = np.multiply(data_x, <span class="number">2</span>) + <span class="number">1</span> + np.random.uniform(<span class="number">-0.5</span>, <span class="number">0.5</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#画图，将x,y的数据投上去</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">ax.scatter(data_x, data_y)</span><br><span class="line">plt.ion()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>这里看下图吧<br><img src="https://i.imgur.com/96MSzxY.png" alt=""><br>这里的点点就是我们的数据，大概按一条斜线分布，所以我们找到一条回归线来拟合这些数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#准备好placeholder,占位符，也叫容器，也就是个坑，用来放数据的</span></span><br><span class="line">x_placeholder = tf.placeholder(tf.float32, name=<span class="string">'X'</span>)</span><br><span class="line">y_placeholder = tf.placeholder(tf.float32, name=<span class="string">'Y'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#变量，</span></span><br><span class="line">W = tf.Variable(dtype=tf.float32,name=<span class="string">'W'</span>,initial_value=tf.random_normal([<span class="number">1</span>]))</span><br><span class="line">b = tf.Variable(dtype=tf.float32,name=<span class="string">'W'</span>,initial_value=tf.random_normal([<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#y_pred 给出回归式的Op</span></span><br><span class="line">y_pred = tf.add(tf.multiply(x_placeholder,W),b)</span><br><span class="line"></span><br><span class="line"><span class="comment">#求loss,给出优化器</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y_placeholder-y_pred,name=<span class="string">'loss'</span>))</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化变量</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment">#session会话</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">	<span class="comment">#迭代100次</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        total_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(data_x,data_y ):</span><br><span class="line">			<span class="comment">#将之前graph中的loss和optimizer跑起来，训练过程就在这，因为有个minimize(loss)的操作	</span></span><br><span class="line">            _, los = sess.run([optimizer, loss], feed_dict=&#123;x_placeholder: x, y_placeholder: y&#125;)</span><br><span class="line">            total_loss += los</span><br><span class="line">		<span class="comment">#求预测值</span></span><br><span class="line">        yp = sess.run(y_pred,feed_dict=&#123;x_placeholder:data_x, y_placeholder: data_y&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">			<span class="comment">#每5步画一次线</span></span><br><span class="line">            lines = ax.plot(data_x, yp, <span class="string">'r-'</span>, lw=<span class="number">5</span>)</span><br><span class="line">            print(<span class="string">'Epoch &#123;0&#125;: &#123;1&#125;'</span>.format(i, total_loss / <span class="number">100</span>))</span><br><span class="line">            plt.pause(<span class="number">0.1</span>)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">			<span class="comment">#为了不让线一直赖着不走，我们每画完就要删除。</span></span><br><span class="line">                ax.lines.pop(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                print(<span class="string">'error'</span>)</span><br></pre></td></tr></table></figure>
<p>这里总结一下。本例解决的是一个线性回归问题，用tensorflow仍先画图，再运行。当然，还有准备数据。<br>其中画图部分包括：占位符定义，变量（权重）定义，运算式定义，loss定义，再加上一个让Loss减小的优化器<br>运行部分包括：将数据喂给相应的op，并run起来，画图操作是为了让大家更直观。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2018/04/27/tensorflow学习笔记3/">
    <time datetime="2018-04-27T13:43:27.000Z" class="entry-date">
        2018-04-27
    </time>
</a>
    
    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>

    </footer>
</article>






  
    <article id="post-tensorflow学习笔记2" class="post-tensorflow学习笔记2 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2018/04/26/tensorflow学习笔记2/">tensorflow学习笔记2</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://xurui.club/2018/04/26/tensorflow学习笔记2/" data-id="cjisx1u73000oowdazbt5nspe" class="leave-reply bdsharebuttonbox" data-cmd="more">分享</a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>上期我们说到tensorflow分两步，Graph和run。在公司用tensorflow搭了下lstm做分类的模型，结果很奇怪。同样的模型结构，我用Keras跑出来auc为0.7,而用tensorflow时loss一直跳，而且auc基本在0.5左右。然后在排错过程中，我想到了graph，把graph打出来后，发现了几个问题，如最后一层忘记加sigmoid激活。 尴尬！！！不过反映了tensorflow graph的一个好处，可以让我们像看图一样检查模型。。。 今天主要讲下常量，变量和占位符。</p>
<p>常量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = tf.contant([3,6])#表示生成一个长度为2的向量a = [3,6]，此时a是一个op，在sess.run之后才有值</span><br><span class="line">#tf.zeros()</span><br><span class="line">#tf.ones()</span><br><span class="line">#都为常量</span><br><span class="line">######------------------</span><br><span class="line">#tf.random_normal(shape=,dtype=,name=&apos;&apos;)</span><br><span class="line">#tf.random_uniform()</span><br><span class="line">#以上也是常量，只不过是随机常量</span><br></pre></td></tr></table></figure></p>
<p>变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">b = tf.Variable(2,name=&apos;scalar&apos;)#生成一个变量，并为该变量赋初值为2，仍在sess.run()后才有值为2。</span><br><span class="line">#变量在使用之前要初始化！！！初始化变量有三种方式</span><br><span class="line">#1）全部初始化</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line">#2)初始化部分变量</span><br><span class="line">init_ab = tf.variables_initializer([a,b],name =&apos;init_ab&apos;)</span><br><span class="line">#3)初始化单个变量</span><br><span class="line">sess.run(b.initializer)</span><br><span class="line">#当然，此时b被初始化后是个Tensor,</span><br><span class="line">print(b) #Tensor(&apos;Variable/....&apos;)</span><br><span class="line">print(b.eval()) #[[0.444,0.111,....],...,[...]],使用eval()输出变量内容a</span><br></pre></td></tr></table></figure></p>
<p>记得常量为一个op,而Variable()是一个类<br>占位符placeholder()</p>
<p><code>a = tf.placeholder(dtype,shape=,name=&#39;&#39;)</code>占位符就是个容器，先占个坑，里面什么都没有，在run的时候，可以通过 <code>sess.run([a,b],feed_dict={a:a_data,b:b_data})</code>来将值放到之前占的坑里。 一般我们用占位符来存放用于训练的数据，当然我们可以直接用数据来构建op，但是有点外行了。。用placeholder的方式，可以让我们数据送入的更自由，可以按自己需要的batch来送入。<br>简单总结一下，常量constant()用来构建一些在模型中不需要改变的量，变量Variable()一般用来构建权重等，需要不断更新，占位符placeholder一般用来作数据的容器。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2018/04/26/tensorflow学习笔记2/">
    <time datetime="2018-04-26T13:43:27.000Z" class="entry-date">
        2018-04-26
    </time>
</a>
    
    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>

    </footer>
</article>






  
    <article id="post-tensorflow学习笔记1" class="post-tensorflow学习笔记1 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2018/04/26/tensorflow学习笔记1/">tensorflow学习笔记1</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://xurui.club/2018/04/26/tensorflow学习笔记1/" data-id="cjisx1u6w000howdaanbmucc8" class="leave-reply bdsharebuttonbox" data-cmd="more">分享</a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>明天要去实习了，心里有些激动，有些紧张，还有些舍不得，舍不得学校的样子，和某个人。</p>
<p>进入正题。</p>
<p>tensorflow是谷歌开源的一款深度学习框架，我用的是python，这个框架是目前最火的框架之一，很有学习的必要。</p>
<p>首先tensorflow，tensor +　flow，tensor –&gt; 张量，flow –&gt;流动, 也就是张量在图里流动。这里讲两点，张量就是，0维的叫标量（数字），1维的叫向量，2维的叫矩阵，那3+维只能叫张量了;而在图里流动，这里的图（graph）是tensorflow的重要思想之一，tensorflow把运算结构画成graph，其中有节点op，有边，边代表张量的流动，节点代表运算。</p>
<p>在tensorflow代码中，分为两大块，第一块用来画图，即把所有的运算画在一张图上，并没有实际运算；第二块用来运算，Session().这样做看似很麻烦，其实有个好处，我们看到了图之后，可以有选择性的运算某些节点，而一些没必要的节点可以不运算，节约了大量的时间。如下面的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">x=2</span><br><span class="line"></span><br><span class="line">y=3</span><br><span class="line"></span><br><span class="line">add_op=tf.add(x,y)</span><br><span class="line"></span><br><span class="line">mul_op=tf.mul(x,y)</span><br><span class="line"></span><br><span class="line">useless=tf.mul(x,add_op)</span><br><span class="line"></span><br><span class="line">pow_op=tf.pow(add_op,mul_op)</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line"></span><br><span class="line">     z=sess.run(pow_op)</span><br></pre></td></tr></table></figure></p>
<p><img src="/image/1.jpg" alt=""></p>
<p>可以看到如果只<code>run(pow_op)</code>,那么<code>useless</code>就不会被运算。原因是，当我们<code>run</code>时，会从图中找该op所依赖的op，而<code>pow_op</code>没有依赖<code>useless</code>,所以就没有执行啦。<br>记得查看graph的时候，可不是像打开jpg一样哟。。要<code>cd</code>到graph存放的目录下，<code>Tensorboard --logdir=&#39;目录 &#39;</code>才行。<br>待续。。。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2018/04/26/tensorflow学习笔记1/">
    <time datetime="2018-04-26T13:43:20.000Z" class="entry-date">
        2018-04-26
    </time>
</a>
    
    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>

    </footer>
</article>






  
    <article id="post-找实习" class="post-找实习 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2018/04/26/找实习/">找实习</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://xurui.club/2018/04/26/找实习/" data-id="cjisx1u75000rowda0qh59boo" class="leave-reply bdsharebuttonbox" data-cmd="more">分享</a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>说件开心的事，我种的海棠花开了。</p>
<p>再说件开心的事，讯飞实习录用了，上午接到的电话，下周二入职。</p>
<p>这个实习等好久了，前段时间看到大家都在找实习，心里发慌，于是自己也厚着脸皮找朋友内推。蚂蚁金服的一面，就给我拒了，心里的酸，每天早上天没亮就往外反，搞得每天都睡不好觉，感觉自己找不到工作了。可能从来没找过工作，没接受过这种刺激，那几天还在调整心情，也感激下我的小女友，一直给我鼓励。后来一边投实习，一边总结经验，感觉没有实践经验是很大的减分项，所以又找朋友帮我推了下讯飞的实习，这个不是暑期实习，所以面试相对简单些，结束后朋友告诉我主管对我印象还不错，应该通过了。可是，人事部一直没给通知。总担心那边出什么意外情况，这两天脑海里上演了好多大戏，也被自己的戏给吓到过。不过还好，终于还是给了通知，虽然有点晚。</p>
<p>晚上，本来想去科大参加腾讯的宣讲，谁曾想临时改了场地，在另一个校区，干脆不去了，坐下来老老实实的做携程的笔试题，前面的选择和问答题还好，选择题基本都是基础知识，考点也比较细。问答有个基因的条件概率题，大概做出来了，还一道讲一下深度学习中，relu比sigmoid和tanh好在什么地方。最后一个题，编程，没看懂题，这里记录一下。最长路径问题。</p>
<p>现有ABCDE五个字符，以及M个字符串，每个字符串由这五个字符和1-9的整数间隔组成，如：A2B3D，表示存在A-&gt;B B-&gt;D的路径，且路径长为2和3，可以推出A-&gt;D的一条路径长为5.求最长的一条路径的长度，如果任何一处路径出现环（如A-&gt;…-&gt;A的路径），则返回-1.<br>输入： 第一行 为字符串的个数M 第二行 开始为M个字符串<br>输出： 最长的一条路径的长度，如果出现环，返回-1<br>如输入 4 A2B3D 、 A4C2E 、 A5D、 C3B<br>输出 10</p>
<p>刚开始理解错了，所以信心满满写了20分钟代码，最后测试没通过。等读懂题，黄花菜早结冰了。。</p>
<p>这些笔试编程题都比较奇葩，多做做应该会有不小进步。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2018/04/26/找实习/">
    <time datetime="2018-04-26T13:33:45.000Z" class="entry-date">
        2018-04-26
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/心情/">心情</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/心情/">心情</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/面试/">面试</a></li></ul>

    </footer>
</article>






  
    <article id="post-初来博客" class="post-初来博客 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2018/04/26/初来博客/">初来博客</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://xurui.club/2018/04/26/初来博客/" data-id="cjisx1u6z000kowda48bkzx3j" class="leave-reply bdsharebuttonbox" data-cmd="more">分享</a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>我的第一篇博客，也不知道写点啥。</p>
<p>研究生生涯转眼间过去了大半，曾经的舒适区已经渐渐被现实挤得越来越小。细细想来，过去的这段时间，我究竟在忙些什么？想了很久，才知道答案：瞎忙。</p>
<p>在本科时候，自己学习了JAVA EE开发，也做过一些小网站，本来要去找工作，可是拿到了保研名额，所以想在舒适区里再窝几年，那个时候的我，虽然怂，不敢面对陌生的人生，可是却有着不可一世的傲气，因为我是专业前三，因为我是安徽省优秀毕业生，因为我是学霸，其实说到底，因为我顶着光环，或者说我意想出来的光环。</p>
<p>读研，进研究所，接触了机器学习和自然语言处理，发现自己原来会的JAVA开发只是皮毛中的皮毛，我自诩精通技术，却对Machine Learning和NLP一无所知，于是我开始变得谦逊，因为实在没有底气骄傲，尴尬，哈哈。。。</p>
<p>现在，研二生活也渐渐近尾声，常常有种恐惧感，就像风筝要飞了，手中的线越来越少，你看到了，却无能为力。还好，有篇论文已经写出来了，在投，在等结果；Machine Learning 和 NLP也算入门（不敢吹牛），一些算法也做过推导和代码编写。从开始不懂LR（逻辑回归），到现在懂了一点，也算进步吧。哈哈，开玩笑，懂了不只一点，比一点多一些。</p>
<p>那压力在哪呢？在找工作。</p>
<p>前两天投了几个实习，结果不太乐观。面试知识点比较细，虽然基本都能答上来，但总是给人一种不太精通的感觉。所以最近也在恶补数学原理和代码实现，毕竟这是理科和工科的结合嘛。说到这，不禁有点疑问，为什么非要做人工智能相关呢？明明不会，何苦为难。我也说不清，只是感觉这个有挑战有乐趣，工作不就应该这些么？比尔说过一句话：人们往往高估自己一年内能做的事，却又低估自己十年内能做的事。可能我现在还有半只脚在门外，不过认定一个目标往前走，总有踏进去的一天吧。</p>
<p>回想自己这两年研，AI坚持在学，毕竟想吃这碗饭；也在坚持健身，常常弹琴；有人爱，有事做，有所期待。</p>
<p>我在瞎忙？<br>好像不是。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2018/04/26/初来博客/">
    <time datetime="2018-04-26T12:46:40.000Z" class="entry-date">
        2018-04-26
    </time>
</a>
    
    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/心情/">心情</a></li></ul>

    </footer>
</article>






  
  
    <nav id="pagination">
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
      </nav>
    </nav>
  

</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    <aside id="search" class="widget widget_search"><form role="search" method="get" accept-charset="utf-8" id="searchform" class="searchform" action="//google.com/search">
    <div>
        <input type="text" value="" name="s" id="s" />
        <input type="submit" id="searchsubmit" value="搜索" />
    </div>
</form></aside>
  
    
  
    
  <aside class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-content">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/心情/">心情</a><span class="category-list-count">1</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Recents</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/2018/06/22/capsnet/">揭开迷雾，来一顿美味的Capsule盛宴</a>
          </li>
        
          <li>
            <a href="/2018/06/19/kmaxpooling/">k-max-pooling的keras实现</a>
          </li>
        
          <li>
            <a href="/2018/06/11/interview/">n阶乘后面有多少个0</a>
          </li>
        
          <li>
            <a href="/2018/06/05/python-1/">python数据存储利器之pickle</a>
          </li>
        
          <li>
            <a href="/2018/06/01/lda/">lda主题模型python实现篇</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Tags</h3>
    <div class="widget-content">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/">Keras</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lda/">lda</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/">pandas</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/">tensorflow</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/异常解决/">异常解决</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/心情/">心情</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/技术/">技术</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据分析/">数据分析</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/胶囊网络/">胶囊网络</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试/">面试</a><span class="tag-list-count">2</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget-content tagcloud">
      <a href="/tags/Keras/" style="font-size: 12.5px;">Keras</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/lda/" style="font-size: 10px;">lda</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/异常解决/" style="font-size: 12.5px;">异常解决</a> <a href="/tags/心情/" style="font-size: 12.5px;">心情</a> <a href="/tags/技术/" style="font-size: 10px;">技术</a> <a href="/tags/数据分析/" style="font-size: 10px;">数据分析</a> <a href="/tags/深度学习/" style="font-size: 17.5px;">深度学习</a> <a href="/tags/胶囊网络/" style="font-size: 10px;">胶囊网络</a> <a href="/tags/面试/" style="font-size: 12.5px;">面试</a>
    </div>
  </aside>

  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <p>&copy; 2018 Petrus Zhang
    All rights reserved.</p>
    <p>My Way to Better!</p>
</footer>


  <span>Hosted by <a href="https://pages.coding.me" >Coding Pages</a></span>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

<script src="/js/jquery-2.0.3.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div>
</body>
</html>